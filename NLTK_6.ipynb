{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b05803f",
   "metadata": {},
   "source": [
    "# **CPC353 Lab 6**\n",
    "* In this session, you will need the gensim library. Install it using pip install gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f5556",
   "metadata": {},
   "source": [
    "## **Long Short-Term Memory (LSTM)**\n",
    "\n",
    "Long Short-Term Memory (LSTM) is a type of deep learning model, specifically a Recurrent Neural Network (RNN), designed to understand and predict sequential data by remembering important information over long periods, overcoming the vanishing gradient problem that limits standard RNNs. To put it simply, LSTMs process data points one after another, maintaining a \"memory\" of previous inputs, making them ideal for text, audio, and time-series data.\n",
    "\n",
    "Meanwhile, a sequence of a text means words appear in order, and earlier words can affect the meaning of later ones. Unlike a feedforward neural network, which treats text as a fixed set of features and ignores word order, an LSTM processes words one by one and maintains an internal memory that captures context across the sequence. This allows it to model word order and handle variable-length texts naturally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c3754",
   "metadata": {},
   "source": [
    "## **Step 1: Library Import & GloVe**\n",
    "\n",
    "GloVe (Global Vectors for Word Representation) is an unsupervised learning algorithm designed to generate dense vector representations also known as embeddings. Its primary objective is to capture semantic relationships between words by analyzing their co-occurrence patterns in a large text corpus. GloVe has pre-defined dense vectors for around every 6 billion words of English literature along with many other characters like commas, braces and semicolons. It can be downloaded and used immediately in many natural language processing (NLP) applications. Users can select a pre-trained GloVe embedding in a dimension like 50d, 100d, 200d or 300d vectors that best fits their needs in terms of computational resources and task specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d22de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "from nltk import TweetTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load a pretrained GloVe word embedding model (50-dimensional vectors) using gensim\n",
    "model_glove = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6252c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"movie\" - Shape: (50,), Value:\n",
      "[ 0.30824   0.17223  -0.23339   0.023105  0.28522   0.23076  -0.41048\n",
      " -1.0035   -0.2072    1.4327   -0.80684   0.68954  -0.43648   1.1069\n",
      "  1.6107   -0.31966   0.47744   0.79395  -0.84374   0.064509  0.90251\n",
      "  0.78609   0.29699   0.76057   0.433    -1.5032   -1.6423    0.30256\n",
      "  0.30771  -0.87057   2.4782   -0.025852  0.5013   -0.38593  -0.15633\n",
      "  0.45522   0.04901  -0.42599  -0.86402  -1.3076   -0.29576   1.209\n",
      " -0.3127   -0.72462  -0.80801   0.082667  0.26738  -0.98177  -0.32147\n",
      "  0.99823 ]\n",
      "\n",
      "\"hello\" - Shape: (50,), Value:\n",
      "[-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(f\"\\\"movie\\\" - Shape: {model_glove[\"movie\"].shape}, Value:\\n{model_glove[\"movie\"]}\\n\")\n",
    "print(f\"\\\"hello\\\" - Shape: {model_glove[\"hello\"].shape}, Value:\\n{model_glove[\"hello\"]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb79fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=50, 400000 keys>\n"
     ]
    }
   ],
   "source": [
    "print(model_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ff142",
   "metadata": {},
   "source": [
    "## **Step 2: Tokenization & Sequence Padding**\n",
    "\n",
    "In this step, raw text documents are transformed into fixed-length numerical sequences that can be fed into a neural network such as an LSTM. First, tokenization is applied to each document. Tokenization breaks a sentence into smaller units using TweetTokenizer. Next, each token is mapped to a word embedding (50-dimension vector) using the pretrained GloVe model, thus producing a sequence of vectors for each document. Since different documents contain different numbers of words, these sequences naturally have variable lengths.\n",
    "\n",
    "However, neural networks require inputs of uniform size, so sequence padding is used to standardize all documents to the same length. A maximum sentence length (e.g. sent_length = 15) is chosen. Documents shorter than this length are padded with zero vectors, while longer documents are truncated to keep only the first or last 15 tokens (depending on the padding strategy). After padding, every document has the same shape (sent_length, embedding_dim), making it suitable for batch training in an LSTM. By default, if a sequence is shorter than the target length, zeros are inserted at the start of the sequence to make it the required length (pre-padding). Conversely, if a sequence is longer than the target length, the earlier elements are discarded, and only the last portion of the sequence is retained (pre-truncating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bf86412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding: (5, 50), Tokens: ['i', 'love', 'the', 'movies', '!']\n",
      "Embedding: (5, 50), Tokens: ['the', 'actors', 'are', 'great', '.']\n",
      "Embedding: (3, 50), Tokens: ['beautiful', 'actress', ':)']\n",
      "Embedding: (6, 50), Tokens: ['i', 'do', 'not', 'like', 'the', 'music']\n",
      "Embedding: (2, 50), Tokens: ['nice', 'story']\n",
      "Embedding: (10, 50), Tokens: ['actors', 'are', 'great', ',', 'but', 'overall', 'is', 'not', 'nice', '.']\n",
      "Embedding: (3, 50), Tokens: ['love', 'it', '!']\n",
      "Embedding: (2, 50), Tokens: ['great', '...']\n",
      "Embedding: (5, 50), Tokens: ['enjoy', 'it', 'very', 'much', '.']\n",
      "Embedding: (3, 50), Tokens: ['wonderful', 'experience', '.']\n",
      "Embedding: (2, 50), Tokens: ['really', 'boring']\n",
      "Embedding: (1, 50), Tokens: [':(']\n",
      "Embedding: (2, 50), Tokens: ['bad', 'acting']\n",
      "Embedding: (6, 50), Tokens: ['i', 'do', 'not', 'like', 'the', 'actors']\n",
      "Embedding: (6, 50), Tokens: ['fall', 'asleep', 'throughout', 'the', 'movie', '!']\n",
      "Embedding: (7, 50), Tokens: ['too', 'much', 'dialogs', 'and', 'not', 'much', 'actions']\n",
      "\n",
      "X Shape: (16, 15, 50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = ['I love the movies!',\n",
    "        'The actors are great.',\n",
    "        'Beautiful actress :)',\n",
    "        \"i do not like the music\",\n",
    "        'nice story',\n",
    "        'actors are great, but overall is not nice.',\n",
    "        'love it!',\n",
    "        'great...',\n",
    "        'enjoy it very much.',\n",
    "        'Wonderful experience.',\n",
    "        'really boring',\n",
    "        ':(',\n",
    "        'Bad acting',\n",
    "        \"I do not like the actors\",\n",
    "        \"Fall asleep throughout the movie!\",\n",
    "        \"too much dialogs and not much actions\"]\n",
    "\n",
    "cat = [1, 1, 1, \n",
    "       0, 1, 0,\n",
    "       1, 1, 1, \n",
    "       1, 0, 0,\n",
    "       0, 0, 0, \n",
    "       0]\n",
    "\n",
    "sent_length = 15\n",
    "n_features = 50\n",
    "n_output = 2\n",
    "batch_size = 4\n",
    "\n",
    "# Tokenize the text in the document and append to a list\n",
    "tokenizer = TweetTokenizer()\n",
    "docs_embedding = list()\n",
    "for d in docs:\n",
    "    tokens = tokenizer.tokenize(d.lower())\n",
    "    embedding = model_glove[tokens]\n",
    "    docs_embedding.append(embedding)\n",
    "    print(f\"Embedding: {embedding.shape}, Tokens: {tokens}\")\n",
    "\n",
    "# Pad the embedding sequence so that they have the same sentence length\n",
    "X = sequence.pad_sequences(docs_embedding, maxlen = sent_length, dtype = \"int32\")\n",
    "X = np.array(X)\n",
    "print(f\"\\nX Shape: {str(X.shape)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d1f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding index 0:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0\n",
      "   1 -2 -1  0  1 -1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   1 -1 -1  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 -1  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0 -1  0  1  0  0  0  0  1  0  0  0  0  0  1  0  0  1\n",
      "   0  0 -1  0  0 -1  2  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 -1 -1  0  0 -1  2  0 -1  1 -1  0  0 -1  0  0  0  0  0  0  0  0  0 -1\n",
      "   0  0]]\n",
      "\n",
      "X index 0:\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 -1  0  1  0  0  0  0  0  0  0  0  0\n",
      "   1 -2 -1  0  1 -1  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   1 -1 -1  0  1  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 -1  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0 -1  0  1  0  0  0  0  1  0  0  0  0  0  1  0  0  1\n",
      "   0  0 -1  0  0 -1  2  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 -1 -1  0  0 -1  2  0 -1  1 -1  0  0 -1  0  0  0  0  0  0  0  0  0 -1\n",
      "   0  0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print(f\"Embedding index 0:\\n{np.array(docs_embedding[0]).astype(int)}\\n\")\n",
    "print(f\"X index 0:\\n{X[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfed938",
   "metadata": {},
   "source": [
    "## **Step 3: LSTM Model Training & Prediction**\n",
    "\n",
    "In Step 3, the LSTM model is constructed, trained, and used for prediction. The predicted labels are then compared to the true labels to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b334631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │           <span style=\"color: #00af00; text-decoration-color: #00af00\">424</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)]         │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m2\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, │           \u001b[38;5;34m424\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m2\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)]         │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m62\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486</span> (1.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m486\u001b[0m (1.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">486</span> (1.90 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m486\u001b[0m (1.90 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.4375 - loss: 0.6919 - val_accuracy: 0.4375 - val_loss: 0.6881\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4375 - loss: 0.6876 - val_accuracy: 0.4375 - val_loss: 0.6856\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4375 - loss: 0.6849 - val_accuracy: 0.4375 - val_loss: 0.6831\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4375 - loss: 0.6823 - val_accuracy: 0.4375 - val_loss: 0.6804\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5000 - loss: 0.6798 - val_accuracy: 0.5625 - val_loss: 0.6778\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5625 - loss: 0.6773 - val_accuracy: 0.5625 - val_loss: 0.6752\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5625 - loss: 0.6745 - val_accuracy: 0.6250 - val_loss: 0.6724\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6716 - val_accuracy: 0.6250 - val_loss: 0.6696\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6250 - loss: 0.6690 - val_accuracy: 0.6250 - val_loss: 0.6666\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6660 - val_accuracy: 0.6250 - val_loss: 0.6637\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6629 - val_accuracy: 0.6875 - val_loss: 0.6607\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6875 - loss: 0.6596 - val_accuracy: 0.6875 - val_loss: 0.6577\n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6875 - loss: 0.6567 - val_accuracy: 0.6875 - val_loss: 0.6544\n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6875 - loss: 0.6535 - val_accuracy: 0.7500 - val_loss: 0.6511\n",
      "Epoch 15/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.6501 - val_accuracy: 0.7500 - val_loss: 0.6477\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.6467 - val_accuracy: 0.7500 - val_loss: 0.6443\n",
      "Epoch 17/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7500 - loss: 0.6429 - val_accuracy: 0.8125 - val_loss: 0.6408\n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.6394 - val_accuracy: 0.8125 - val_loss: 0.6372\n",
      "Epoch 19/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8125 - loss: 0.6360 - val_accuracy: 0.8125 - val_loss: 0.6334\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8125 - loss: 0.6322 - val_accuracy: 0.8750 - val_loss: 0.6295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\n",
      "Prediction Probability:\n",
      "[[0.48394838 0.5160517 ]\n",
      " [0.4860027  0.51399726]\n",
      " [0.48133528 0.5186647 ]\n",
      " [0.5502376  0.44976237]\n",
      " [0.47482103 0.5251789 ]\n",
      " [0.5850275  0.41497242]\n",
      " [0.50229776 0.49770218]\n",
      " [0.49488652 0.5051135 ]\n",
      " [0.50440204 0.49559805]\n",
      " [0.49950713 0.5004928 ]\n",
      " [0.5134975  0.4865025 ]\n",
      " [0.5038352  0.4961648 ]\n",
      " [0.5308633  0.46913674]\n",
      " [0.57115656 0.42884344]\n",
      " [0.5779668  0.4220332 ]\n",
      " [0.6423412  0.3576588 ]]\n",
      "\n",
      "Predicted Class Label: [1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0]\n",
      "\n",
      "Accuracy Score: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM layer for computation\n",
    "inputs = Input(shape = (sent_length, n_features))\n",
    "lstm = LSTM(2, return_sequences = True, return_state = True)\n",
    "outputs_seq, state_h, state_c = lstm(inputs)\n",
    "flat = Flatten()(outputs_seq)\n",
    "outputs = Dense(n_output, activation = 'softmax')(flat)\n",
    "\n",
    "# Wrap the LSTM layer into a Keras model, connecting the input and output layers to form a single end-to-end model\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the keras model\n",
    "model.fit(X, to_categorical(cat), validation_data = (X, to_categorical(cat)),\n",
    "          epochs = 20, verbose = 1, batch_size = batch_size)\n",
    "\n",
    "# Evaluate the keras model\n",
    "prob = model.predict(X)\n",
    "test = np.argmax(prob, axis = 1)\n",
    "\n",
    "print(f\"\\nPrediction Probability:\\n{prob}\")\n",
    "print(f\"\\nPredicted Class Label: {test}\")\n",
    "print(f\"\\nAccuracy Score: {accuracy_score(cat, test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "353as2 (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
